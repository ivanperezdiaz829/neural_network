{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a21e4eb",
   "metadata": {},
   "source": [
    "Primer Trabajo FSI: Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e1842",
   "metadata": {},
   "source": [
    "Importamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "480ef872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import kagglehub\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb060023",
   "metadata": {},
   "source": [
    "Como tenemos una carpeta con las imágenes y otra con las etiquetas (YOLO) lo primero que debemos hacer es modificar este formato para tener un fichero csv con las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4ee8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando dataset: pkdarabi/cardetection\n",
      "Dataset descargado en: C:\\Users\\Daniel\\.cache\\kagglehub\\datasets\\pkdarabi\\cardetection\\versions\\5\n",
      "\n",
      "Escaneando imágenes en: C:\\Users\\Daniel\\.cache\\kagglehub\\datasets\\pkdarabi\\cardetection\\versions\\5\\car\\train\\images\n",
      "\n",
      "--- Resumen ---\n",
      "Total de cajas delimitadoras encontradas: 4298\n",
      "Conteo de objetos por clase (Índice):\n",
      "clase_indice\n",
      "0     542\n",
      "1     585\n",
      "2      19\n",
      "3     267\n",
      "4     101\n",
      "5     252\n",
      "6     285\n",
      "7     334\n",
      "8     235\n",
      "9     283\n",
      "10    301\n",
      "11    318\n",
      "12    323\n",
      "13    168\n",
      "14    285\n",
      "Name: count, dtype: int64\n",
      "¡CSV creado exitosamente en: yolo_labels_dataset.csv!\n"
     ]
    }
   ],
   "source": [
    "# --- Configuración del Dataset de KaggleHub ---\n",
    "# Reemplaza con el ID de tu dataset en KaggleHub. \n",
    "# Formato: 'owner/dataset-slug/version' o 'owner/dataset-slug'\n",
    "KAGGLE_DATASET_ID = 'pkdarabi/cardetection' \n",
    "\n",
    "# 1. Descargar el dataset usando kagglehub\n",
    "# Esto descargará y descomprimirá el dataset en una ubicación temporal/cache.\n",
    "print(f\"Descargando dataset: {KAGGLE_DATASET_ID}\")\n",
    "# 'download' devuelve la ruta local donde se guardó el dataset.\n",
    "KAGGLE_DOWNLOAD_PATH = kagglehub.dataset_download(KAGGLE_DATASET_ID)\n",
    "print(f\"Dataset descargado en: {KAGGLE_DOWNLOAD_PATH}\")\n",
    "\n",
    "# --- Configuración de Rutas (Ajustadas a la descarga) ---\n",
    "# **¡Ajuste crucial!** Reemplaza 'train/images' y 'train/labels' si tu dataset\n",
    "# tiene una estructura de subcarpeta diferente (ej: 'images', 'labels' directamente).\n",
    "# La mayoría de los datasets YOLO tienen una carpeta de 'train' o 'data'.\n",
    "\n",
    "# Definición de las rutas finales\n",
    "IMAGEN_DIR = os.path.join(KAGGLE_DOWNLOAD_PATH, 'car', 'train', 'images') \n",
    "ETIQUETAS_DIR = os.path.join(KAGGLE_DOWNLOAD_PATH, 'car', 'train', 'labels') \n",
    "CSV_SALIDA = 'yolo_labels_dataset.csv'\n",
    "EXTENSION_IMAGEN = '.jpg'\n",
    "EXTENSION_ETIQUETA = '.txt'\n",
    "\n",
    "datos = []\n",
    "\n",
    "print(f\"\\nEscaneando imágenes en: {IMAGEN_DIR}\")\n",
    "\n",
    "# 2. Iterar sobre los archivos de imagen para emparejar\n",
    "if not os.path.exists(IMAGEN_DIR):\n",
    "    print(f\"ERROR: No se encontró el directorio de imágenes en {IMAGEN_DIR}. Revisa la estructura del dataset de KaggleHub.\")\n",
    "else:\n",
    "    for archivo_imagen in os.listdir(IMAGEN_DIR):\n",
    "        if archivo_imagen.lower().endswith(EXTENSION_IMAGEN):\n",
    "            # El nombre base (sin extensión) es la clave de emparejamiento\n",
    "            nombre_base = os.path.splitext(archivo_imagen)[0]\n",
    "            \n",
    "            # 3. Construir la ruta al archivo de etiqueta\n",
    "            ruta_etiqueta = os.path.join(ETIQUETAS_DIR, nombre_base + EXTENSION_ETIQUETA)\n",
    "            \n",
    "            if os.path.exists(ruta_etiqueta):\n",
    "                \n",
    "                # 4. Leer el archivo de etiqueta\n",
    "                with open(ruta_etiqueta, 'r') as f:\n",
    "                    lineas = f.readlines()\n",
    "                \n",
    "                # 5. Procesar cada línea (cada objeto/bounding box)\n",
    "                for linea in lineas:\n",
    "                    partes = linea.strip().split()\n",
    "                    \n",
    "                    if len(partes) == 5:\n",
    "                        # El primer valor es la CLASE (entero), el resto son coordenadas (flotantes)\n",
    "                        clase_idx = int(partes[0])\n",
    "                        x_center = float(partes[1])\n",
    "                        y_center = float(partes[2])\n",
    "                        width = float(partes[3])\n",
    "                        height = float(partes[4])\n",
    "                        \n",
    "                        # 6. Almacenar los datos\n",
    "                        datos.append({\n",
    "                            'nombre_archivo': archivo_imagen,\n",
    "                            'clase_indice': clase_idx,\n",
    "                            'x_center': x_center,\n",
    "                            'y_center': y_center,\n",
    "                            'width': width,\n",
    "                            'height': height\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f\"¡Advertencia! Línea con formato incorrecto en {ruta_etiqueta}: {linea.strip()}\")\n",
    "            else:\n",
    "                # Nota: Es común en detección que algunas imágenes no tengan objetos (no hay archivo .txt)\n",
    "                # Si esto ocurre, la imagen no tendrá entradas en el CSV (lo cual es correcto).\n",
    "                pass\n",
    "                # print(f\"¡Advertencia! No se encontró el archivo de etiqueta para: {archivo_imagen}\")\n",
    "\n",
    "\n",
    "# 7. Crear el DataFrame y guardarlo\n",
    "df = pd.DataFrame(datos)\n",
    "df.to_csv(CSV_SALIDA, index=False)\n",
    "\n",
    "print(\"\\n--- Resumen ---\")\n",
    "print(f\"Total de cajas delimitadoras encontradas: {len(df)}\")\n",
    "if not df.empty:\n",
    "    print(\"Conteo de objetos por clase (Índice):\")\n",
    "    print(df['clase_indice'].value_counts().sort_index())\n",
    "print(f\"¡CSV creado exitosamente en: {CSV_SALIDA}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b56d9",
   "metadata": {},
   "source": [
    "Ahora ya podemos crear una instancia de la clase YOLODataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd9fb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipo de objeto creado: <class '__main__.YOLODataset'>\n",
      "Número total de imágenes (longitud del dataset): 3527\n",
      "Forma del Tensor de la Imagen [0]: torch.Size([3, 416, 416])\n",
      "Forma del Tensor de Cajas [0]: torch.Size([1, 5])\n",
      "Ejemplo de Cajas (primeras 3): \n",
      "tensor([[7.0000, 0.5337, 0.3173, 0.1695, 0.3173]])\n"
     ]
    }
   ],
   "source": [
    "# --- CÓDIGO PARA GENERAR EL DATASET ---\n",
    "IMAGE_SIZE = (416, 416) \n",
    "DATA_DIR = './'\n",
    "LABELS_NAME = 'yolo_labels_dataset.csv'\n",
    "\n",
    "# 1. Definir transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "\n",
    "# 2. Clase para Detección de Objetos (SIN CAMBIOS)\n",
    "class YOLODataset(Dataset):\n",
    "    def __init__(self, archivo_csv, directorio_imagenes, transform=None):\n",
    "        self.full_labels_df = pd.read_csv(archivo_csv)\n",
    "        self.directorio_imagenes = directorio_imagenes\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imagenes_unicas = self.full_labels_df['nombre_archivo'].unique()\n",
    "        self.labels_grouped = self.full_labels_df.groupby('nombre_archivo')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imagenes_unicas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.imagenes_unicas[idx]\n",
    "        image_path = os.path.join(self.directorio_imagenes, image_name)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        boxes_df = self.labels_grouped.get_group(image_name)\n",
    "        \n",
    "        labels_tensor = torch.tensor(\n",
    "            boxes_df[['clase_indice', 'x_center', 'y_center', 'width', 'height']].values, \n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, labels_tensor\n",
    "\n",
    "\n",
    "# 2. Definir las rutas usando la ruta de descarga de Kaggle\n",
    "ruta_csv = os.path.join(DATA_DIR, LABELS_NAME) # El CSV se creó en el directorio actual\n",
    "# IMPORTANTE: Definir la ruta de imágenes APUNTANDO al subdirectorio 'train/images'\n",
    "ruta_imgs = os.path.join(KAGGLE_DOWNLOAD_PATH, 'car', 'train', 'images') \n",
    "\n",
    "# 3. Crear instancia del Dataset\n",
    "if not os.path.exists(ruta_csv) or not os.path.exists(ruta_imgs):\n",
    "    print(\"Error: Asegúrate de que el CSV existe y que la ruta de imágenes de Kaggle es correcta.\")\n",
    "else:\n",
    "    dataset_yolo = YOLODataset(archivo_csv=ruta_csv, directorio_imagenes=ruta_imgs, transform=transform)\n",
    "    print(f\"\\nTipo de objeto creado: {type(dataset_yolo)}\")\n",
    "    print(f\"Número total de imágenes (longitud del dataset): {len(dataset_yolo)}\")\n",
    "\n",
    "    # Ejemplo de acceso al primer elemento:\n",
    "    if len(dataset_yolo) > 0:\n",
    "        img_tensor, boxes_tensor = dataset_yolo[0]\n",
    "        print(f\"Forma del Tensor de la Imagen [0]: {img_tensor.shape}\")\n",
    "        print(f\"Forma del Tensor de Cajas [0]: {boxes_tensor.shape}\")\n",
    "        print(f\"Ejemplo de Cajas (primeras 3): \\n{boxes_tensor[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d15e6",
   "metadata": {},
   "source": [
    "El siguiente paso será crear el DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9693eff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataLoader creado con éxito. Número de batches: 221\n"
     ]
    }
   ],
   "source": [
    "# --- Configuración del Loader ---\n",
    "BATCH_SIZE = 16 # Tamaño de batch comúnmente usado en detección de objetos.\n",
    "\n",
    "# 1. Definir la función de colación (collate_fn)\n",
    "def yolo_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Función de colación personalizada para detección de objetos.\n",
    "    Agrupa las imágenes en un solo tensor y las etiquetas en una lista.\n",
    "    \"\"\"\n",
    "    # Separar imágenes y etiquetas (cajas)\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch] # Cada target es un tensor [N_i, 5]\n",
    "\n",
    "    # Apilar las imágenes en un único tensor [B, C, H, W]\n",
    "    images_tensor = torch.stack(images, dim=0)\n",
    "    \n",
    "    # Devolver las etiquetas como una lista. La lista contiene los tensores de cajas\n",
    "    # de tamaño variable, uno por imagen en el batch.\n",
    "    targets_list = targets\n",
    "    \n",
    "    return images_tensor, targets_list\n",
    "\n",
    "# 2. Crear el DataLoader\n",
    "train_loader = DataLoader(\n",
    "    dataset_yolo, # El dataset ya inicializado en el código anterior\n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, # Barajar los datos para el entrenamiento\n",
    "    collate_fn=yolo_collate_fn, # ¡Crucial para detección de objetos!\n",
    "    num_workers=4 # Opcional: Para cargar datos más rápido\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoader creado con éxito. Número de batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5279d4",
   "metadata": {},
   "source": [
    "A continuación creamos la red neuronal que entrenaremos con el dataset que hemos creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a72875",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(416*416, 512) # \n",
    "        self.fc2 = nn.Linear(512, 128)    # Capa oculta con 128 neuronas\n",
    "        self.fc3 = nn.Linear(128, 15)      # Capa de salida con 10 clases (0-14)\n",
    "        self.activation = nn.Sigmoid()        # Función de activación Sigmoide\n",
    "        self.softmax = nn.Softmax(dim=1)  # Función softmax para la capa de salida\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 416*416)            # Aplanar la imagen de 416x416 a un vector de 173056\n",
    "        #print(x.shape)                  # Mostrar la forma del tensor después de aplanarlo\n",
    "        x = self.fc1(x)                \n",
    "        x = self.activation(x)            # Función de activación Sigmoide en la capa oculta\n",
    "        #print(x.shape)                   # Mostrar la forma del tensor después de la primera capa\n",
    "        x = self.fc2(x)                  # Capa de salida\n",
    "        x = self.activation(x)\n",
    "        x = self.fc3(x)\n",
    "        #print(x.shape)                   # Mostrar la forma del tensor después de la segunda capa\n",
    "        x = self.softmax(x)              # Aplicar softmax para obtener probabilidades\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15193ef",
   "metadata": {},
   "source": [
    "Definimos la función de perdida y el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93507421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 512]      88,605,184\n",
      "           Sigmoid-2                  [-1, 512]               0\n",
      "            Linear-3                  [-1, 128]          65,664\n",
      "           Sigmoid-4                  [-1, 128]               0\n",
      "            Linear-5                   [-1, 15]           1,935\n",
      "           Softmax-6                   [-1, 15]               0\n",
      "================================================================\n",
      "Total params: 88,672,783\n",
      "Trainable params: 88,672,783\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.98\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 338.26\n",
      "Estimated Total Size (MB): 340.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNN()\n",
    "summary(model, (3, 416, 416)) # Resumen del modelo\n",
    "# El modelo y las dimension de entrad de los datos\n",
    "\n",
    "criterion = nn.MSELoss() # Función de pérdida (Mean Squared Error)\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),  # Parámetros del modelo\n",
    "    lr=0.01 # ESTO ES MUY IMPORTANTE, LA TASA DE APRENDIZAJE!!!!!!!!!\n",
    ") # Optimizador (Stochastic Gradient Descent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
